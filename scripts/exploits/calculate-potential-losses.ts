import { createWriteStream, existsSync, mkdirSync, renameSync } from 'fs';
import { join } from 'path';
import { ChainId } from '@revoke.cash/chains';
import { Redis } from '@upstash/redis';
import { type CsvFormatterStream, format, parseFile } from 'fast-csv';
import { getScriptLogsProvider } from 'lib/ScriptLogsProvider';
import { ERC20_ABI } from 'lib/abis';
import { COINGECKO_API_BASE_URL, COINGECKO_API_KEY } from 'lib/constants';
import ky from 'lib/ky';
import { addressToTopic, deduplicateArray, isNullish, sortTokenEventsChronologically } from 'lib/utils';
import { createViemPublicClientForChain, getChainExplorerUrl, getChainName, isSupportedChain } from 'lib/utils/chains';
import { isLogResponseSizeError, isNetworkError } from 'lib/utils/errors';
import { type Erc20ApprovalEvent, TokenEventType, parseApprovalLog } from 'lib/utils/events';
import { getExploitBySlug } from 'lib/utils/exploits';
import { formatFixedPointBigInt, shortenAddress } from 'lib/utils/formatting';
import { type Erc20TokenContract, createTokenContract } from 'lib/utils/tokens';
import PQueue from 'p-queue';
import { type Address, type Block, type PublicClient, getAbiItem, toEventSelector } from 'viem';

mkdirSync(join(__dirname, 'data', 'temp'), { recursive: true });

const EXPLOIT = process.argv[2];
const OUTPUT_FILE = join(__dirname, 'data', `${EXPLOIT}.csv`);
const P_QUEUE = new PQueue({ concurrency: 500 });

if (!EXPLOIT) {
  console.error('Usage: node scripts/exploits/calculate-potential-losses.ts <exploit-slug>');
  process.exit(1);
}

if (!COINGECKO_API_KEY) {
  console.error('No Coingecko API key found in environment variables');
  process.exit(1);
}

const CSV_HEADERS = [
  'Chain',
  'Revoke Transaction',
  'User Address',
  'Token Address',
  'Token Symbol',
  'Potential Loss (Token)',
  'Price (USD)',
  'Potential Loss (USD)',
];

const CSV_WRITER = format({ headers: CSV_HEADERS });

const PRICE_CACHE = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL,
  token: process.env.UPSTASH_REDIS_REST_TOKEN,
});

const assetPlatformsPromise = ky
  .get(`${COINGECKO_API_BASE_URL}/asset_platforms`, { headers: { 'x-cg-pro-api-key': COINGECKO_API_KEY } })
  .json<Array<{ id: string; chain_identifier: number }>>();

const calculateSavedTokensForExploit = async (exploitSlug: string) => {
  const exploit = await getExploitBySlug(exploitSlug);

  const logger = new Logger({ exploitSlug });
  logger.log(`Checking exploit with date ${exploit.date}`);

  const timestamp = Math.floor(new Date(exploit.date).getTime() / 1000);

  CSV_WRITER.pipe(createWriteStream(OUTPUT_FILE));

  // We're doing this sequentially because we're running out of memory for lifi-2024 otherwise
  for (const contract of exploit.addresses) {
    await calculateSavedTokensForContract(exploit.slug, contract.address, contract.chainId, timestamp);
  }

  CSV_WRITER.end();
};

const calculateSavedTokensForContract = async (
  exploitSlug: string,
  address: Address,
  chainId: number,
  timestamp: number,
) => {
  const logger = new Logger({ exploitSlug, chainId, address });

  // Unfortunately, Fuse does not support historical eth_call requests, so we skip it
  if (!isSupportedChain(chainId) || chainId === ChainId.FuseMainnet) {
    logger.log('Skipping unsupported chain');
    return;
  }

  const tempFile = join(__dirname, 'data', 'temp', `${exploitSlug}-${address}-${chainId}.csv`);

  if (existsSync(tempFile)) {
    logger.log(`Writing results from temp file ${tempFile}`);

    const parser = parseFile(tempFile, { headers: true });

    // For some reason, this doesn't work
    // parser.pipe(CSV_WRITER);

    // So we do this instead
    parser.on('data', (row) => {
      CSV_WRITER.write(row);
    });

    return new Promise<void>((resolve, reject) => {
      parser.on('end', () => {
        resolve();
      });

      parser.on('error', (error) => {
        reject(error);
      });
    });
  }

  logger.log('Finding last block before exploit date');
  const client = createViemPublicClientForChain(chainId);

  // If we don't have a documented blockCreated number for multicall3, we assume it's not deployed yet (historically)
  if (client.chain?.contracts?.multicall3 && !client.chain?.contracts?.multicall3.blockCreated) {
    // biome-ignore lint/performance/noDelete: we need to get rid of the multicall contract since we're doing historic requests
    delete client.chain?.contracts;
  }

  const toBlock = await findBlockByTimestamp(client, timestamp);
  if (!toBlock) throw new Error(`No block found on ${getChainName(chainId)} at ${timestamp}`);

  const uniqueRevocations = await getUniqueRevocationsForContract(exploitSlug, address, chainId, toBlock);
  logger.log(`Calculating potential losses prevented by ${uniqueRevocations.length} revocations`);

  const tempWriter = format({ headers: CSV_HEADERS });
  tempWriter.pipe(createWriteStream(`${tempFile}-temp.csv`));

  await Promise.all(
    uniqueRevocations.map((event, index) =>
      P_QUEUE.add(async () => {
        logger.log(
          `Calculating potential loss for revocation ${index + 1} of ${uniqueRevocations.length} (${P_QUEUE.size} tasks in queue)`,
        );

        return calculatePotentialLoss(client, event, toBlock, tempWriter);
      }),
    ),
  );

  try {
    renameSync(`${tempFile}-temp.csv`, tempFile);
  } catch {}

  logger.log(`Calculated potential losses for ${uniqueRevocations.length} revocations`);
};

const calculatePotentialLoss = async (
  client: PublicClient,
  event: Erc20ApprovalEvent,
  block: Block,
  tempWriter: CsvFormatterStream<string[], string[]>,
): Promise<void> => {
  const logger = new Logger({ exploitSlug: EXPLOIT, chainId: event.chainId, address: event.token });

  try {
    const tokenContract = createTokenContract(event, client) as Erc20TokenContract;

    const balancePromise = client.readContract({
      ...tokenContract,
      functionName: 'balanceOf',
      args: [event.owner],
      blockNumber: BigInt(block.number!),
    });

    const tokenSymbolPromise = client.readContract({
      ...tokenContract,
      functionName: 'symbol',
      blockNumber: BigInt(block.number!),
    });

    const tokenDecimalsPromise = client.readContract({
      ...tokenContract,
      functionName: 'decimals',
      blockNumber: BigInt(block.number!),
    });

    const [balance, tokenSymbol, tokenDecimals] = await Promise.all([
      balancePromise,
      tokenSymbolPromise,
      tokenDecimalsPromise,
    ]);

    const tokenPrice = await getPriceForToken(event.chainId, event.token, Number(block.timestamp));

    const formattedLoss = formatFixedPointBigInt(balance, tokenDecimals, 0, 18).replace(/,/g, ''); // Remove thousands separators
    if (formattedLoss === '0' || formattedLoss.includes('<')) return;

    const lossUsd = isNullish(tokenPrice) ? '' : (tokenPrice * Number(formattedLoss)).toFixed(2);
    if (lossUsd === '0.00') return;

    const chainName = getChainName(event.chainId);
    const transactionUrl = `${getChainExplorerUrl(event.chainId)}/tx/${event.time.transactionHash}`;
    const userUrl = `${getChainExplorerUrl(event.chainId)}/address/${event.owner}`;
    const tokenUrl = `${getChainExplorerUrl(event.chainId)}/address/${event.token}`;

    tempWriter.write([
      chainName,
      transactionUrl,
      userUrl,
      tokenUrl,
      tokenSymbol,
      formattedLoss,
      tokenPrice ?? '',
      lossUsd,
    ]);

    CSV_WRITER.write([
      chainName,
      transactionUrl,
      userUrl,
      tokenUrl,
      tokenSymbol,
      formattedLoss,
      tokenPrice ?? '',
      lossUsd,
    ]);
  } catch (error) {
    logger.log(`Error calculating potential loss: ${error}`);

    // Network errors should be retried (also checking for LogResponseSizeError since that produces false negatives)
    if (isNetworkError(error) || isLogResponseSizeError(error)) {
      await new Promise((resolve) => setTimeout(resolve, 1000));
      logger.log('Retrying after error');
      return calculatePotentialLoss(client, event, block, tempWriter);
    }
  }
};

const getUniqueRevocationsForContract = async (
  exploitSlug: string,
  address: Address,
  chainId: number,
  toBlock: Block,
): Promise<Erc20ApprovalEvent[]> => {
  const logger = new Logger({ exploitSlug, chainId, address });
  logger.log(`Getting logs up until ${toBlock.number}`);

  const logsProvider = getScriptLogsProvider(chainId);

  const rawLogs = await logsProvider.getLogs({
    fromBlock: 0,
    toBlock: Number(toBlock.number),
    topics: [toEventSelector(getAbiItem({ abi: ERC20_ABI, name: 'Approval' })), null, addressToTopic(address)],
  });
  logger.log(`Found ${rawLogs.length} logs`);

  // O(n)
  const parsedEvents = rawLogs
    .map((log) => parseApprovalLog(log, chainId))
    .filter((event) => event?.type === TokenEventType.APPROVAL_ERC20);
  logger.log(`Parsed ${parsedEvents.length} events`);

  // Sort the logs in reverse chronological order and remove duplicates by token+owner, so that only the most
  // recent event prt token per owner is kept
  // O(n log n)
  const sortedEvents = sortTokenEventsChronologically(parsedEvents).reverse();
  logger.log(`Sorted ${sortedEvents.length} events`);

  // O(n)
  const uniqueEvents = deduplicateArray(sortedEvents, (event) => `${event.owner}-${event.token}`);
  logger.log(`Deduplicated ${uniqueEvents.length} events`);

  // Only return revocations (amount === 0)
  return uniqueEvents.filter((event) => event.payload.amount === BigInt(0));
};

const findBlockByTimestamp = async (
  client: PublicClient,
  targetTimestamp: number,
  fromBlock = 1,
  toBlockArg?: number,
): Promise<Block | null> => {
  const toBlock = toBlockArg ?? Number(await client.getBlockNumber());
  if (fromBlock > toBlock) return null;

  const firstBlock = await client.getBlock({ blockNumber: BigInt(fromBlock) });
  const lastBlock = await client.getBlock({ blockNumber: BigInt(toBlock) });

  // Calculate the block difference between the first and last block
  const blockDiff = toBlock - fromBlock;

  // Calculate the time difference between the first and last block
  const timeDiff = Number(lastBlock.timestamp) - Number(firstBlock.timestamp);

  // Calculate the percentage of the time difference that has passed
  const percentageTimeDiff = (targetTimestamp - Number(firstBlock.timestamp)) / timeDiff;

  // Calculate the block number where the target date is likely to be
  const estimatedBlockNumber = Math.floor(fromBlock + percentageTimeDiff * blockDiff);

  if (estimatedBlockNumber === fromBlock) return firstBlock;
  if (estimatedBlockNumber === toBlock) return lastBlock;

  const estimatedBlock = await client.getBlock({ blockNumber: BigInt(estimatedBlockNumber) });

  if (estimatedBlock.timestamp > targetTimestamp) {
    return findBlockByTimestamp(client, targetTimestamp, fromBlock, estimatedBlockNumber);
  }

  if (estimatedBlock.timestamp < targetTimestamp) {
    return findBlockByTimestamp(client, targetTimestamp, estimatedBlockNumber, toBlock);
  }

  return estimatedBlock;
};

interface CoingeckoPriceResponse {
  prices: [number, number][];
}

const getPriceForToken = async (chainId: number, token: Address, timestamp: number): Promise<number | undefined> => {
  // For some reason, Coingecko doesn't have a price for some tokens on Polygon, so we use corresponding Ethereum tokens instead
  if (chainId === ChainId.PolygonMainnet) {
    const tokenMapping: Record<Address, Address> = {
      '0xc2132D05D31c914a87C6611C10748AEb04B58e8F': '0xdAC17F958D2ee523a2206206994597C13D831ec7', // USDT
      '0x7ceB23fD6bC0adD59E62ac25578270cFf1b9f619': '0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2', // WETH
      '0x8f3Cf7ad23Cd3CaDbD9735AFf958023239c6A063': '0x6B175474E89094C44Da98b954EedeAC495271d0F', // DAI
      '0x2791Bca1f2de4661ED88A30C99A7a9449Aa84174': '0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48', // USDC
    };

    if (tokenMapping[token]) {
      // biome-ignore lint/style/noParameterAssign: we need to change the chainId to get the price
      chainId = ChainId.EthereumMainnet;
      // biome-ignore lint/style/noParameterAssign: we need to change the token to get the price
      token = tokenMapping[token];
    }
  }

  const assetPlatforms = await assetPlatformsPromise;
  const assetPlatform = assetPlatforms.find((platform) => platform.chain_identifier === chainId);
  if (!assetPlatform) return undefined;

  const cacheKey = `token-price:${chainId}-${token}-${timestamp}`;
  const cachedPrice = await PRICE_CACHE.get<number>(cacheKey);
  if (cachedPrice === -1) return undefined;
  if (cachedPrice !== null) return cachedPrice;

  const fromTimestamp = timestamp - 24 * 60 * 60;
  const toTimestamp = Date.now() / 1000; // If a price is not available for that specific timestamp, we use the earliest available price
  const url = `${COINGECKO_API_BASE_URL}/coins/${assetPlatform.id}/contract/${token}/market_chart/range?vs_currency=usd&from=${fromTimestamp}&to=${toTimestamp}&interval=daily&precision=full`;

  try {
    const result = await ky
      .get(url, { headers: { 'x-cg-pro-api-key': COINGECKO_API_KEY }, cache: 'no-store' })
      .json<CoingeckoPriceResponse>();

    const price = result.prices?.[0]?.[1];
    await PRICE_CACHE.set(cacheKey, price);

    return price;
  } catch (error) {
    await PRICE_CACHE.set(cacheKey, -1);
    return undefined;
  }
};

interface LoggerOptions {
  exploitSlug: string;
  chainId?: number;
  address?: Address;
}

class Logger {
  constructor(private options: LoggerOptions) {}

  log(message: string) {
    const { exploitSlug, chainId, address } = this.options;

    if (chainId && address) {
      console.log(`[${exploitSlug}] ${getChainName(chainId)} | ${shortenAddress(address)} - ${message}`);
    } else {
      console.log(`[${exploitSlug}] ${message}`);
    }
  }
}

calculateSavedTokensForExploit(EXPLOIT);
