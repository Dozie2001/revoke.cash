import { createWriteStream, existsSync, mkdirSync, renameSync } from 'fs';
import { join } from 'path';
import { ChainId } from '@revoke.cash/chains';
import { Redis } from '@upstash/redis';
import { type CsvFormatterStream, format, parseFile } from 'fast-csv';
import { getScriptLogsProvider } from 'lib/ScriptLogsProvider';
import { ERC20_ABI } from 'lib/abis';
import { COINGECKO_API_BASE_URL, COINGECKO_API_KEY } from 'lib/constants';
import ky from 'lib/ky';
import { addressToTopic, deduplicateArray, isNullish, sortTokenEventsChronologically } from 'lib/utils';
import { createViemPublicClientForChain, getChainExplorerUrl, getChainName, isSupportedChain } from 'lib/utils/chains';
import { isLogResponseSizeError, isNetworkError } from 'lib/utils/errors';
import { type Erc20ApprovalEvent, TokenEventType, parseApprovalLog } from 'lib/utils/events';
import { getAllExploits, getExploitBySlug } from 'lib/utils/exploits';
import { formatFixedPointBigInt, shortenAddress } from 'lib/utils/formatting';
import { type Erc20TokenContract, createTokenContract } from 'lib/utils/tokens';
import PQueue from 'p-queue';
import { type Address, type Block, type PublicClient, getAbiItem, toEventSelector } from 'viem';
import { getTokenCoingeckoId, mapToken } from './price-mappings';

mkdirSync(join(__dirname, 'data', 'temp'), { recursive: true });

const EXPLOIT = process.argv[2];
const P_QUEUE = new PQueue({ concurrency: 500 });

// Coingecko has a rate limit of 500 requests per minute, so we need to throttle our requests
// We go under that limit by a good amount to be safe
const COINGECKO_QUEUE = new PQueue({ interval: 1000, intervalCap: 5 });

const priceFailures: Record<number, Record<string, number>> = {};

if (!COINGECKO_API_KEY) {
  console.error('No Coingecko API key found in environment variables');
  process.exit(1);
}

const CSV_HEADERS = [
  'Chain',
  'Revoke Transaction',
  'User Address',
  'Token Address',
  'Token Symbol',
  'Potential Loss (Token)',
  'Price (USD)',
  'Potential Loss (USD)',
];

const PRICE_CACHE = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL,
  token: process.env.UPSTASH_REDIS_REST_TOKEN,
});

const assetPlatformsPromise = ky
  .get(`${COINGECKO_API_BASE_URL}/asset_platforms`, { headers: { 'x-cg-pro-api-key': COINGECKO_API_KEY } })
  .json<Array<{ id: string; chain_identifier: number }>>();

const calculateSavedTokensForExploit = async (exploitSlug: string) => {
  const exploit = await getExploitBySlug(exploitSlug);

  const logger = new Logger({ exploitSlug });
  logger.log(`Checking exploit with date ${exploit.date}`);

  const timestamp = Math.floor(new Date(exploit.date).getTime() / 1000);

  const csvWriter = format({ headers: CSV_HEADERS });
  const outputFile = join(__dirname, 'data', `${exploitSlug}.csv`);
  csvWriter.pipe(createWriteStream(outputFile));

  // We're doing this sequentially because we're running out of memory for lifi-2024 otherwise
  for (const contract of exploit.addresses) {
    await calculateSavedTokensForContract(exploit.slug, contract.address, contract.chainId, timestamp, csvWriter);
  }

  csvWriter.end();
};

const calculateSavedTokensForAllExploits = async () => {
  const exploits = await getAllExploits();

  for (const exploit of exploits) {
    if (exploit.slug === 'multichain-2023') continue;
    await calculateSavedTokensForExploit(exploit.slug);
  }
};

const calculateSavedTokensForContract = async (
  exploitSlug: string,
  address: Address,
  chainId: number,
  timestamp: number,
  csvWriter: CsvFormatterStream<string[], string[]>,
) => {
  const logger = new Logger({ exploitSlug, chainId, address });

  // Unfortunately, Fuse does not support historical eth_call requests, so we skip it
  if (!isSupportedChain(chainId) || chainId === ChainId.FuseMainnet) {
    logger.log('Skipping unsupported chain');
    return;
  }

  const tempFile = join(__dirname, 'data', 'temp', `${exploitSlug}-${address}-${chainId}.csv`);

  if (existsSync(tempFile)) {
    logger.log(`Writing results from temp file ${tempFile}`);
    return await writeFromTempFile(tempFile, csvWriter);
  }

  logger.log('Finding last block before exploit date');
  const client = createViemPublicClientForChain(chainId);

  // If we don't have a documented blockCreated number for multicall3, we assume it's not deployed yet (historically)
  if (client.chain?.contracts?.multicall3 && !client.chain?.contracts?.multicall3.blockCreated) {
    // biome-ignore lint/performance/noDelete: we need to get rid of the multicall contract since we're doing historic requests
    delete client.chain?.contracts;
  }

  const toBlock = await findBlockByTimestamp(client, timestamp);
  if (!toBlock) throw new Error(`No block found on ${getChainName(chainId)} at ${timestamp}`);

  const uniqueRevocations = await getUniqueRevocationsForContract(exploitSlug, address, chainId, toBlock);
  logger.log(`Calculating potential losses prevented by ${uniqueRevocations.length} revocations`);

  const tempWriter = format({ headers: CSV_HEADERS });
  tempWriter.pipe(createWriteStream(`${tempFile}-temp.csv`));

  await Promise.all(
    uniqueRevocations.map((event, index) =>
      P_QUEUE.add(async () => {
        logger.log(
          `Calculating potential loss for revocation ${index + 1} of ${uniqueRevocations.length} (${P_QUEUE.size} tasks in queue)`,
        );

        return calculatePotentialLoss(client, event, toBlock, tempWriter);
      }),
    ),
  );

  try {
    renameSync(`${tempFile}-temp.csv`, tempFile);
  } catch {}

  logger.log(`Calculated potential losses for ${uniqueRevocations.length} revocations`);
  await writeFromTempFile(tempFile, csvWriter);
};

const writeFromTempFile = async (tempFile: string, csvWriter: CsvFormatterStream<string[], string[]>) => {
  const parser = parseFile(tempFile, { headers: true });

  // For some reason, this doesn't work
  // parser.pipe(CSV_WRITER);

  // So we do this instead
  parser.on('data', (row) => {
    csvWriter.write(row);
  });

  return new Promise<void>((resolve, reject) => {
    parser.on('end', () => {
      resolve();
    });

    parser.on('error', (error) => {
      reject(error);
    });
  });
};

const calculatePotentialLoss = async (
  client: PublicClient,
  event: Erc20ApprovalEvent,
  block: Block,
  tempWriter: CsvFormatterStream<string[], string[]>,
): Promise<void> => {
  const logger = new Logger({ exploitSlug: EXPLOIT, chainId: event.chainId, address: event.token });

  try {
    const tokenContract = createTokenContract(event, client) as Erc20TokenContract;

    const balancePromise = client.readContract({
      ...tokenContract,
      functionName: 'balanceOf',
      args: [event.owner],
      blockNumber: BigInt(block.number!),
    });

    const tokenSymbolPromise = client.readContract({
      ...tokenContract,
      functionName: 'symbol',
      blockNumber: BigInt(block.number!),
    });

    const tokenDecimalsPromise = client.readContract({
      ...tokenContract,
      functionName: 'decimals',
      blockNumber: BigInt(block.number!),
    });

    const [balance, tokenSymbol, tokenDecimals] = await Promise.all([
      balancePromise,
      tokenSymbolPromise,
      tokenDecimalsPromise,
    ]);

    const tokenPrice = await getPriceForToken(event.chainId, event.token, Number(block.timestamp));

    const formattedLoss = formatFixedPointBigInt(balance, tokenDecimals, 0, 18).replace(/,/g, ''); // Remove thousands separators
    if (formattedLoss === '0' || formattedLoss.includes('<')) return;

    const lossUsd = isNullish(tokenPrice) ? '' : (tokenPrice * Number(formattedLoss)).toFixed(2);
    if (lossUsd === '0.00') return;

    const chainName = getChainName(event.chainId);
    const transactionUrl = `${getChainExplorerUrl(event.chainId)}/tx/${event.time.transactionHash}`;
    const userUrl = `${getChainExplorerUrl(event.chainId)}/address/${event.owner}`;
    const tokenUrl = `${getChainExplorerUrl(event.chainId)}/address/${event.token}`;

    tempWriter.write([
      chainName,
      transactionUrl,
      userUrl,
      tokenUrl,
      tokenSymbol,
      formattedLoss,
      tokenPrice ?? '',
      lossUsd,
    ]);
  } catch (error) {
    logger.log(`Error calculating potential loss: ${error}`);

    // Network errors should be retried (also checking for LogResponseSizeError since that produces false negatives)
    if (isNetworkError(error) || isLogResponseSizeError(error)) {
      await new Promise((resolve) => setTimeout(resolve, 1000));
      logger.log('Retrying after error');
      return calculatePotentialLoss(client, event, block, tempWriter);
    }
  }
};

const getUniqueRevocationsForContract = async (
  exploitSlug: string,
  address: Address,
  chainId: number,
  toBlock: Block,
): Promise<Erc20ApprovalEvent[]> => {
  const logger = new Logger({ exploitSlug, chainId, address });
  logger.log(`Getting logs up until ${toBlock.number}`);

  const logsProvider = getScriptLogsProvider(chainId);

  const rawLogs = await logsProvider.getLogs({
    fromBlock: 0,
    toBlock: Number(toBlock.number),
    topics: [toEventSelector(getAbiItem({ abi: ERC20_ABI, name: 'Approval' })), null, addressToTopic(address)],
  });
  logger.log(`Found ${rawLogs.length} logs`);

  // O(n)
  const parsedEvents = rawLogs
    .map((log) => parseApprovalLog(log, chainId))
    .filter((event) => event?.type === TokenEventType.APPROVAL_ERC20);
  logger.log(`Parsed ${parsedEvents.length} events`);

  // Sort the logs in reverse chronological order and remove duplicates by token+owner, so that only the most
  // recent event prt token per owner is kept
  // O(n log n)
  const sortedEvents = sortTokenEventsChronologically(parsedEvents).reverse();
  logger.log(`Sorted ${sortedEvents.length} events`);

  // O(n)
  const uniqueEvents = deduplicateArray(sortedEvents, (event) => `${event.owner}-${event.token}`);
  logger.log(`Deduplicated ${uniqueEvents.length} events`);

  // Only return revocations (amount === 0)
  return uniqueEvents.filter((event) => event.payload.amount === BigInt(0));
};

const findBlockByTimestamp = async (
  client: PublicClient,
  targetTimestamp: number,
  fromBlock = 1,
  toBlockArg?: number,
): Promise<Block | null> => {
  const toBlock = toBlockArg ?? Number(await client.getBlockNumber());
  if (fromBlock > toBlock) return null;

  const firstBlock = await client.getBlock({ blockNumber: BigInt(fromBlock) });
  const lastBlock = await client.getBlock({ blockNumber: BigInt(toBlock) });

  // Calculate the block difference between the first and last block
  const blockDiff = toBlock - fromBlock;

  // Calculate the time difference between the first and last block
  const timeDiff = Number(lastBlock.timestamp) - Number(firstBlock.timestamp);

  // Calculate the percentage of the time difference that has passed
  const percentageTimeDiff = (targetTimestamp - Number(firstBlock.timestamp)) / timeDiff;

  // Calculate the block number where the target date is likely to be
  const estimatedBlockNumber = Math.floor(fromBlock + percentageTimeDiff * blockDiff);

  if (estimatedBlockNumber === fromBlock) return firstBlock;
  if (estimatedBlockNumber === toBlock) return lastBlock;

  const estimatedBlock = await client.getBlock({ blockNumber: BigInt(estimatedBlockNumber) });

  if (estimatedBlock.timestamp > targetTimestamp) {
    return findBlockByTimestamp(client, targetTimestamp, fromBlock, estimatedBlockNumber);
  }

  if (estimatedBlock.timestamp < targetTimestamp) {
    return findBlockByTimestamp(client, targetTimestamp, estimatedBlockNumber, toBlock);
  }

  return estimatedBlock;
};

interface CoingeckoPriceResponse {
  prices: [number, number][];
}

const getPriceForToken = async (chainId: number, token: string, timestamp: number): Promise<number | undefined> => {
  const mappedToken = mapToken(chainId, token);
  if (mappedToken) return getPriceForToken(mappedToken.chainId, mappedToken.token, timestamp);

  try {
    const coingeckoId = getTokenCoingeckoId(chainId, token);
    if (coingeckoId) return getPriceForCoingeckoId(coingeckoId, timestamp);

    const assetPlatforms = await assetPlatformsPromise;
    const assetPlatform = assetPlatforms.find((platform) => platform.chain_identifier === chainId);
    if (!assetPlatform) return undefined;

    const cacheKey = `token-price:${chainId}-${token}-${timestamp}`;
    const cachedPrice = await PRICE_CACHE.get<number>(cacheKey);
    if (cachedPrice === -1) return undefined;
    if (cachedPrice !== null) return cachedPrice;

    const fromTimestamp = timestamp - 24 * 60 * 60;
    const toTimestamp = Math.floor(Date.now() / 1000); // If a price is not available for that specific timestamp, we use the earliest available price
    const url = `${COINGECKO_API_BASE_URL}/coins/${assetPlatform.id}/contract/${token}/market_chart/range?vs_currency=usd&from=${fromTimestamp}&to=${toTimestamp}&interval=daily&precision=full`;

    const result = await COINGECKO_QUEUE.add(
      async () => ky.get(url, { headers: { 'x-cg-pro-api-key': COINGECKO_API_KEY } }).json<CoingeckoPriceResponse>(),
      { throwOnTimeout: true },
    );

    const price = result.prices?.[0]?.[1];
    await PRICE_CACHE.set(cacheKey, price);

    return price;
  } catch (error) {
    console.error(`Error getting price for ${token} on ${chainId} at ${timestamp}: ${error}`);
    priceFailures[chainId] ??= {};
    priceFailures[chainId][token] ??= 0;
    priceFailures[chainId][token]++;
    // await PRICE_CACHE.set(cacheKey, -1);
    return undefined;
  }
};

const getPriceForCoingeckoId = async (coingeckoId: string, timestamp: number): Promise<number | undefined> => {
  const cacheKey = `token-price:coingecko-${coingeckoId}-${timestamp}`;
  const cachedPrice = await PRICE_CACHE.get<number>(cacheKey);
  if (cachedPrice === -1) return undefined;
  if (cachedPrice !== null) return cachedPrice;

  const fromTimestamp = timestamp - 24 * 60 * 60;
  const toTimestamp = Math.floor(Date.now() / 1000); // If a price is not available for that specific timestamp, we use the earliest available price
  const url = `${COINGECKO_API_BASE_URL}/coins/${coingeckoId}/market_chart/range?vs_currency=usd&from=${fromTimestamp}&to=${toTimestamp}&interval=daily&precision=full`;

  const result = await COINGECKO_QUEUE.add(
    async () => ky.get(url, { headers: { 'x-cg-pro-api-key': COINGECKO_API_KEY } }).json<CoingeckoPriceResponse>(),
    { throwOnTimeout: true },
  );

  const price = result.prices?.[0]?.[1];
  await PRICE_CACHE.set(cacheKey, price);

  return price;
};

interface LoggerOptions {
  exploitSlug: string;
  chainId?: number;
  address?: Address;
}

class Logger {
  constructor(private options: LoggerOptions) {}

  log(message: string) {
    const { exploitSlug, chainId, address } = this.options;

    if (chainId && address) {
      console.log(`[${exploitSlug}] ${getChainName(chainId)} | ${shortenAddress(address)} - ${message}`);
    } else {
      console.log(`[${exploitSlug}] ${message}`);
    }
  }
}

if (EXPLOIT) {
  calculateSavedTokensForExploit(EXPLOIT);
} else {
  calculateSavedTokensForAllExploits();
}

process.on('exit', (code) => {
  console.log('Failed to get prices for the following tokens:');
  console.log(JSON.stringify(priceFailures, null, 2));
  process.exit(code);
});

process.on('SIGINT', () => {
  console.log('Failed to get prices for the following tokens:');
  console.log(JSON.stringify(priceFailures, null, 2));
  process.exit();
});
